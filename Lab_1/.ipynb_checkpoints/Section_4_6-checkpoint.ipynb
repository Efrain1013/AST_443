{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04e3ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc61b29",
   "metadata": {},
   "source": [
    "The files we have are:\n",
    "1. Images: 1s blue, 0.5 visible, 0.3 red, \n",
    "2. Darks: 0.5s, 0.7s, 1s, 0.3s, 5s\n",
    "3. Flats: 5s blue, 0.7 visible, 0.3s red, \n",
    "\n",
    "We only load in the files for the exposures and the filters that we used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7524588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 1024, 1024)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----Getting the Dark Images and making a master dark for each filter------------\n",
    "#-------------------Here we're getting the data of each file in-----------------------\n",
    "\n",
    "prefix_dark = [\"one_second_dark.0000000\", \"point_five_dark.0000001\", \"point_three_dark.0000000\"]\n",
    "suffix_dark = \".DARK.FIT\"\n",
    "all_darks = []\n",
    "\n",
    "for file_prefix in prefix_dark:\n",
    "    for i in range(0, 10):\n",
    "        filename = \"pretty_pics/lab1_pretty_pic_\" + file_prefix + str(i) + suffix_dark\n",
    "\n",
    "        with fits.open(filename) as hdul:\n",
    "            all_darks.append(hdul[0].data)\n",
    "\n",
    "dark_1s = all_darks[0:10]\n",
    "dark_point_5s = all_darks[10:20]\n",
    "dark_point_3s = all_darks[20:30]\n",
    "\n",
    "total_darks = [dark_1s, dark_point_5s, dark_point_3s]\n",
    "np.shape(total_darks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ae557",
   "metadata": {},
   "source": [
    "In this box all we are doing is loading in the values for the dark current, assigning the files to lists specifying their exposure time, and combining those lists into one so that we can perform our median stuff all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c94d44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Calculating the median dark image for each of the darks------------------------\n",
    "\n",
    "all_dark_medians = []\n",
    "for i in range(0, len(total_darks)):\n",
    "    values = [total_darks[i][0:10]]\n",
    "    median_values = np.median(values, axis=0)\n",
    "    all_dark_medians.append(median_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5ddf8",
   "metadata": {},
   "source": [
    "Here all were doing is creating the three median dark filters for the three different exposure times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82ee8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Getting the Median Images and making a master dark for each filter------------\n",
    "#-------------------Here we're getting the data of each file in-----------------------\n",
    "\n",
    "prefix_flat = [\"five_second_blue.0000000\", \"point_seven_visible.0000000\", \"point_three_red.0000000\"]\n",
    "suffix = \".FIT\"\n",
    "all_flats = []\n",
    "\n",
    "for file_prefix in prefix_flat:\n",
    "    for i in range(0, 10):\n",
    "        filename = \"pretty_pics/lab1_pretty_pic_flat_\" + file_prefix + str(i) + suffix\n",
    "\n",
    "        with fits.open(filename) as hdul:\n",
    "            all_flats.append(hdul[0].data)\n",
    "\n",
    "flat_5s_blue = all_flats[0:10]\n",
    "flat_point_7s_vis = all_flats[10:20]\n",
    "flat_point_3s_red = all_flats[20:30]\n",
    "\n",
    "total_flats = [flat_5s_blue, flat_point_7s_vis, flat_point_3s_red]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27204a",
   "metadata": {},
   "source": [
    "Now were doing the exact same thing we did for the dark images but now with the flat images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba28999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Calculating the median flat image for each of the flats------------------------\n",
    "\n",
    "all_flat_medians = []\n",
    "for i in range(0, len(total_flats)):\n",
    "    values = [total_flats[i][0:10]]\n",
    "    median_values = np.median(values, axis=0)\n",
    "    all_flat_medians.append(median_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83a856",
   "metadata": {},
   "source": [
    "Making the median flat image in the same way as the dark images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce0f8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#------------------Normalizing the flat images to its mode---------------------------\n",
    "\n",
    "\n",
    "mode_arrays = [stats.mode(all_flat_medians[i].flatten(), keepdims = True) for i in range(0,3)]\n",
    "modes = [mode_arrays[i][0] for i in range(0, 3)]\n",
    "normalized_flats = [all_flat_medians[i] / modes[i] for i in range(0, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9bef9",
   "metadata": {},
   "source": [
    "Here we're just normalizing the median flat images to the mode so that we can divide it out in our final image. If we wanted to use the median we can simply replace stats.mode() with np.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28747acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------Taking in the data for each of the filters------------------------\n",
    "prefix_filter = [\"one_second_blue.0000000\", \"point_five_visible.0000000\", \"point_three_red.0000000\"]\n",
    "suffix = \".FIT\"\n",
    "all_filters_data = []\n",
    "\n",
    "for file_prefix in prefix_filter:\n",
    "    for i in range(0, 10):\n",
    "        filename = \"pretty_pics/lab1_pretty_pic_\" + file_prefix + str(i) + suffix\n",
    "\n",
    "        with fits.open(filename) as hdul:\n",
    "            all_filters_data.append(hdul[0].data)\n",
    "            \n",
    "blue_filter = all_filters_data[0:10]\n",
    "visible_filter = all_filters_data[10:20]\n",
    "red_filter = all_filters_data[20:30]\n",
    "total_filters = [blue_filter, visible_filter, red_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a6034",
   "metadata": {},
   "source": [
    "Just like the darks and the flats we're just taking in and organizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06a0c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------Calculating the median values for each of the filters---------------------------\n",
    "\n",
    "all_filter_medians = []\n",
    "for i in range(0, len(total_filters)):\n",
    "    values = [total_filters[i][0:10]]\n",
    "    median_values = np.median(values, axis=0)\n",
    "    all_filter_medians.append(median_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77fb6b",
   "metadata": {},
   "source": [
    "Once again calculating median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73c757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------Calibrating all of the data for each filter----------------------------\n",
    "norm_filters = []\n",
    "\n",
    "for i in range(0, len(all_filter_medians)):\n",
    "    norm_filters.append((all_filter_medians[i] - all_dark_medians[i]) / all_flat_medians[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74983ec1",
   "metadata": {},
   "source": [
    "In this box we are just calibrating our data now. We are subtracting out the dark current first and then dividing out the respective median flat image. This leaves us with our final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cda7b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------Aligning all the images so that when we plot the rgb values the frames line up------------------------\n",
    "\n",
    "import astroalign as aa\n",
    "\n",
    "aligned_blue, footprint = aa.register(norm_filters[0], norm_filters[1])\n",
    "aligned_red, footprint = aa.register(norm_filters[2], norm_filters[1])\n",
    "\n",
    "\n",
    "hdu1 = fits.PrimaryHDU(aligned_blue)\n",
    "hdu1.writeto(\"pretty_pic_blue.fits\", overwrite=True)\n",
    "\n",
    "hdu2 = fits.PrimaryHDU(aligned_red)\n",
    "hdu2.writeto(\"pretty_pic_red.fits\", overwrite=True)\n",
    "\n",
    "hdu3 = fits.PrimaryHDU(norm_filters[1])\n",
    "hdu3.writeto(\"pretty_pic_green.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88b712",
   "metadata": {},
   "source": [
    "In this last box we are importing astroalign so that we can align our images for when we stack them in the ds9. The visible filter gives us our green values, then red and blue filters giving us red and blue data. We are aligning the red and blue filters to the position of our green image (which is norm_filters[1]), and saving this data seperately as fits files. We can then use the ds9 to stack this data on top of each other and play with the parameters to get our final image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
